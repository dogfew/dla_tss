{
  "name": "voicefilter_phase",
  "n_gpu": 1,
  "preprocessing": {
    "sr": 16000,
    "n_fft": 128,
    "spectrogram": {
      "type": "MelSpectrogram",
      "args": {
        "normalized": false
      }
    },
    "log_spec": true
  },
  "audio": {
    "type": "Audio",
    "args": {
      "n_fft": 511
    }
  },
  "augmentations": {
    "wave": [],
    "spectrogram": []
  },
  "arch": {
    "type": "VoiceFilterPhase",
    "args": {
      "embedder_phase_path": "saved/models/dvec_config/1101_080955/checkpoint-epoch5.pth",
      "embedder_path": "saved/models/dvec_config/1101_073809/checkpoint-epoch5.pth",
      "specnet_path": "saved/models/voicefilter/1101_100712/checkpoint-epoch60.pth"
    }
  },
  "data": {
    "train": {
      "batch_size": 12,
      "num_workers": 5,
      "datasets": [
        {
          "type": "CustomDirAudioDataset",
          "args": {
            "dir": "/home/vladimir/PycharmProjects/TTS/temp_datasets/train_easy"
          }
        }
      ]
    }
  },
  "optimizer": {
    "type": "Adam",
    "args": {
      "lr": 1e-5
    }
  },
  "loss": {
    "type": "L1Loss",
    "args": {}
  },
  "metrics": [
  ],
  "lr_scheduler": {
    "type": "ReduceLROnPlateau",
    "args": {
      "factor": 0.75,
      "patience": 2,
      "cooldown": 1
    }
  },
  "trainer": {
    "epochs": 100,
    "save_dir": "saved/",
    "save_period": 25,
    "verbosity": 2,
    "monitor": "min val_loss",
    "early_stop": 100,
    "visualize": "wandb",
    "wandb_project": "tts_project",
    "grad_norm_clip": 1,
    "use_autocast": true,
    "len_epoch": 100
  }
}

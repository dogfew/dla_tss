{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5cd704-a887-4cd7-8661-9450da8564b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hw_tts.utils.audio import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb83400-4465-4a3d-901c-189bb04d1470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio = Audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c76d60-3fb7-4968-bd95-640d58e3822f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "x = torch.randn(16, 255, 4)\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Resnet block for speaker encoder to obtain speaker embedding\n",
    "    ref to\n",
    "        https://github.com/fatchord/WaveRNN/blob/master/models/fatchord_version.py\n",
    "        and\n",
    "        https://github.com/Jungjee/RawNet/blob/master/PyTorch/model_RawNet.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_dims, out_dims):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_dims, out_dims, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(out_dims, out_dims, kernel_size=1, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(out_dims)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(out_dims)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.maxpool = nn.MaxPool1d(3)\n",
    "        if in_dims != out_dims:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv1d(in_dims, out_dims, kernel_size=1, bias=False)\n",
    "        else:\n",
    "            self.downsample = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.batch_norm1(y)\n",
    "        y = self.prelu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.batch_norm2(y)\n",
    "        if self.downsample:\n",
    "            y += self.conv_downsample(x)\n",
    "        else:\n",
    "            y += x\n",
    "        y = self.prelu2(y)\n",
    "        return self.maxpool(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e161ab10-4e70-458b-8eda-6038d32955f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.9344, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(255, 255)(x).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba42371f-b82a-4e16-a3c8-aed549d393b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(103.1035, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_size, out_size):\n",
    "        super().__init__()\n",
    "        self.first = nn.Sequential(\n",
    "            nn.Conv1d(input_size, out_size, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(out_size),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(out_size, out_size, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(out_size)\n",
    "        )\n",
    "\n",
    "        if input_size != out_size:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(input_size, out_size, kernel_size=1, bias=False)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "        self.second = nn.Sequential(\n",
    "                nn.PReLU(), \n",
    "                nn.MaxPool1d(3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.first(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        y += x\n",
    "        y = self.second(y)\n",
    "        return y\n",
    "ResBlock(255, 255)(x).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4d5141-801b-45ed-be67-9e18463c56d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn((16, 4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2383b4fb-7ca2-46b6-9ecd-e2e3a6879426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalLayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-05):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.normalized_dim = dim\n",
    "        self.beta = nn.Parameter(torch.zeros(dim, 1))\n",
    "        self.gamma = nn.Parameter(torch.ones(dim, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=(1, 2), keepdim=True)\n",
    "        var = x.var(dim=(1, 2), keepdim=True, unbiased=False)\n",
    "        x = self.gamma * (x - mean) / torch.sqrt(var + self.eps) + self.beta\n",
    "        return x\n",
    "\n",
    "    \n",
    "class GlobalLayerNorm2(nn.Module): \n",
    "    def __init__(self, dim): \n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "    def forward(self, x): \n",
    "        B, C, T = x.shape\n",
    "        return self.layernorm(x.view(B, C * T)).view(B, C, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d05e0d49-a0fb-498d-8b27-0b903355fa15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalLayerNorm2(nn.Module): \n",
    "    def __init__(self, dim): \n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(dim)\n",
    "    def forward(self, x): \n",
    "        B, C, T = x.shape\n",
    "        return self.layernorm(x.view(B, C * T)).view(B, C, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6303b0-6352-42d2-a4f5-19d146fa65c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res1 = GlobalLayerNorm2(40)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09effbb4-86c3-49a0-9fae-764d42da568c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res2 = GlobalLayerNorm(4)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d050afa4-84dc-424c-95de-3300a193dac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7022e-06, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res1 - res2).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b8a6132-786c-42f4-b2c0-803549e6220d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=256,\n",
    "                 conv_channels=512,\n",
    "                 kernel_size=3,\n",
    "                 dilation=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, conv_channels, 1),\n",
    "            nn.PReLU(),\n",
    "            GlobalLayerNorm(conv_channels, eps=1e-05),\n",
    "            nn.Conv1d(\n",
    "                conv_channels,\n",
    "                conv_channels,\n",
    "                kernel_size,\n",
    "                groups=conv_channels,\n",
    "                padding=(dilation * (kernel_size - 1)) // 2,\n",
    "                dilation=dilation,\n",
    "                bias=True),\n",
    "            nn.PReLU(),\n",
    "            GlobalLayerNorm(conv_channels, eps=1e-05),\n",
    "            nn.Conv1d(conv_channels, in_channels, 1, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f30ca787-c06f-4b0b-9b4a-f0a8e4cd3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNBlock_Spk(TCNBlock):\n",
    "    def __init__(self, in_channels, spk_embed_dim, conv_channels, kernel_size, dilation):\n",
    "        super().__init__(in_channels + spk_embed_dim, conv_channels, kernel_size, dilation)\n",
    "\n",
    "    def forward(self, x, aux):\n",
    "        aux = aux.unsqueeze(-1).repeat(1, 1, x.shape[-1])\n",
    "        y = torch.cat([x, aux], 1)\n",
    "        return super().forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2daae6d-afc0-4afd-9c68-03a17d55445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=256,\n",
    "                 conv_channels=512,\n",
    "                 kernel_size=3,\n",
    "                 dilation=1, causal=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, conv_channels, 1)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.PReLU(),\n",
    "            GlobalLayerNorm(conv_channels, eps=1e-05),\n",
    "            nn.Conv1d(\n",
    "                conv_channels,\n",
    "                conv_channels,\n",
    "                kernel_size,\n",
    "                groups=conv_channels,\n",
    "                padding=(dilation * (kernel_size - 1)) // 2,\n",
    "                dilation=dilation,\n",
    "                bias=True),\n",
    "            nn.PReLU(),\n",
    "            GlobalLayerNorm(conv_channels, eps=1e-05),\n",
    "            nn.Conv1d(conv_channels, in_channels, 1, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv(x)\n",
    "        y = self.net(y)\n",
    "        return y + x\n",
    "\n",
    "\n",
    "class TCNBlock_Spk(TCNBlock):\n",
    "    \"\"\"\n",
    "    Temporal convolutional network block,\n",
    "        1x1Conv - PReLU - Norm - DConv - PReLU - Norm - SConv\n",
    "        The first tcn block takes additional speaker embedding as inputs\n",
    "    Input: 3D tensor with [N, C_in, L_in]\n",
    "    Input Speaker Embedding: 2D tensor with [N, D]\n",
    "    Output: 3D tensor with [N, C_out, L_out]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels=256,\n",
    "                 spk_embed_dim=100,\n",
    "                 conv_channels=512,\n",
    "                 kernel_size=3,\n",
    "                 dilation=1,\n",
    "                 causal=False):\n",
    "        super().__init__(in_channels, conv_channels, kernel_size, dilation)\n",
    "        self.conv = nn.Conv1d(in_channels + spk_embed_dim, conv_channels, 1)\n",
    "\n",
    "    def forward(self, x, aux):\n",
    "        aux = th.unsqueeze(aux, -1)\n",
    "        aux = aux.repeat(1, 1, x.shape[-1])\n",
    "        y = th.cat([x, aux], 1)\n",
    "        y = self.conv(y)\n",
    "        y = self.net(y.squeeze())\n",
    "        return y + x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
